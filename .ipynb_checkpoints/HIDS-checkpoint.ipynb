{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc4756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from numpy import argmax\n",
    "from numpy import array_equal\n",
    "from numpy import array\n",
    "import statistics\n",
    "\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from keras.metrics import categorical_crossentropy\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd778be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#Checking for tensorflow-GPU\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80070fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unizipped Attack File\n",
      "Unizipped Validation File\n",
      "Unizipped Training File\n",
      "Normal Data     --->  train_normal_data\n",
      "Attack Data     --->  train_attack_data\n",
      "Validation Data --->  train_validation_data\n"
     ]
    }
   ],
   "source": [
    "#Unzipping Attack and Validation folders\n",
    "\n",
    "# Unzip Attack Folder to retrive subfolfers\n",
    "from zipfile import ZipFile\n",
    "file_name = \"Attack_Data_Master.zip\"\n",
    "\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "  zip.extractall()\n",
    "  print('Unizipped Attack File')\n",
    "    \n",
    "# Unzip Validation Folder to retrive subfolfers\n",
    "from zipfile import ZipFile\n",
    "file_name = \"Validation_Data_Master.zip\"\n",
    "\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "  zip.extractall()\n",
    "  print('Unizipped Validation File')\n",
    "    \n",
    "# Unzip Training Folder to retrive subfolfers\n",
    "from zipfile import ZipFile\n",
    "file_name = \"Training_Data_Master.zip\"\n",
    "\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "  zip.extractall()\n",
    "  print('Unizipped Training File')\n",
    "\n",
    "# list holding normal training data\n",
    "train_normal_data = [] \n",
    "\n",
    "\n",
    "\n",
    "from pathlib import Path \n",
    "# list that holds attack vectors\n",
    "train_attack_data = []\n",
    "\n",
    "# Set file path ot the folder for iterations\n",
    "input_dir = Path.cwd() / \"Attack_Data_Master\"\n",
    "# store all the files ending with .txt in a list called files\n",
    "files = list (input_dir.rglob(\"*.txt*\"))\n",
    "# Iterate over all the txt files and append the attack in the list train_attack data\n",
    "for FILE in files:\n",
    "  with open (FILE, 'r') as f:\n",
    "    stringData = (f.read())\n",
    "    string_split_data = stringData.split(\" \")\n",
    "    del (string_split_data[-1])\n",
    "    train_attack_data.append(string_split_data)\n",
    "    \n",
    "\n",
    "for i in range(len(train_attack_data)):\n",
    "  for j in range(len(train_attack_data[i])):\n",
    "    train_attack_data[i][j] = int(train_attack_data[i][j])\n",
    "\n",
    "from pathlib import Path \n",
    "# list that holds validation vectors\n",
    "train_validation_data = []\n",
    "\n",
    "# Set file path ot the folder for iterations\n",
    "input_dir = Path.cwd() / \"Validation_Data_Master\"\n",
    "# store all the files ending with .txt in a list called files\n",
    "files = list (input_dir.rglob(\"*.txt*\"))\n",
    "# Iterate over all the txt files and append the attack in the list train_attack data\n",
    "for FILE in files:\n",
    "  with open (FILE, 'r') as f:\n",
    "    stringData = (f.read())\n",
    "    string_split_data = stringData.split(\" \")\n",
    "    del (string_split_data[-1])\n",
    "    train_validation_data.append(string_split_data)\n",
    "    \n",
    "\n",
    "# list that holds training vectors\n",
    "train_normal_data = []\n",
    "\n",
    "# Set file path ot the folder for iterations\n",
    "input_dir = Path.cwd() / \"Training_Data_Master\"\n",
    "# store all the files ending with .txt in a list called files\n",
    "files = list (input_dir.rglob(\"*.txt*\"))\n",
    "# Iterate over all the txt files and append the attack in the list train_attack data\n",
    "for FILE in files:\n",
    "  with open (FILE, 'r') as f:\n",
    "    stringData = (f.read())\n",
    "    string_split_data = stringData.split(\" \")\n",
    "    del (string_split_data[-1])\n",
    "    train_normal_data.append(string_split_data)\n",
    "    \n",
    "\n",
    "for i in range(len(train_normal_data)):\n",
    "  for j in range(len(train_normal_data[i])):\n",
    "    train_normal_data[i][j] = int(train_normal_data[i][j])\n",
    "print(\"Normal Data     --->  train_normal_data\")\n",
    "print(\"Attack Data     --->  train_attack_data\")\n",
    "print(\"Validation Data --->  train_validation_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca80597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest Request Length is 79\n",
      "Longest Request Length is 2948\n",
      "Average Request Length is 369\n"
     ]
    }
   ],
   "source": [
    "#Statistics of the data\n",
    "\n",
    "#Shortest request\n",
    "shortest_seq = 1000;\n",
    "#Longest request\n",
    "longest_seq = 0;\n",
    "#Average Request size in dataset\n",
    "avg_seq = 0\n",
    "\n",
    "sum = 0;\n",
    "for i in range(len(train_normal_data)):\n",
    "    curr_sequence_length = len(train_normal_data[i])\n",
    "    if curr_sequence_length < shortest_seq:\n",
    "        shortest_seq = curr_sequence_length\n",
    "    if curr_sequence_length > longest_seq:\n",
    "        longest_seq = curr_sequence_length\n",
    "    sum += curr_sequence_length\n",
    "avg_seq = int(sum/len(train_normal_data))\n",
    "\n",
    "print(f\"Shortest Request Length is {shortest_seq}\")\n",
    "print(f\"Longest Request Length is {longest_seq}\")\n",
    "print(f\"Average Request Length is {avg_seq}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56cdf4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4372"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bdda110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of unique system calls in the normal list\n",
    "unique_normal = []\n",
    "# System calls that are present in the attack list but not in normal\n",
    "attack_not_in_normal = []\n",
    "\n",
    "#Appending unique system calls from the normal list\n",
    "for i in range(len(train_normal_data)):\n",
    "    for j in range(len(train_normal_data[i])):\n",
    "        curr_sys_call = train_normal_data[i][j]\n",
    "        if curr_sys_call in unique_normal:\n",
    "            continue\n",
    "        else:\n",
    "            unique_normal.append(curr_sys_call)\n",
    "\n",
    "#Appending unique system calls from the attack list that are not present in normal\n",
    "for i in range(len(train_attack_data)):\n",
    "    for j in range(len(train_attack_data[i])):\n",
    "        curr_sys_call = train_attack_data[i][j]\n",
    "        if curr_sys_call not in unique_normal:\n",
    "            attack_not_in_normal.append(curr_sys_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0244f3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique system calls in normal list\n",
    "len(unique_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcd06eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[324, 324, 324, 324, 324, 324, 324, 173, 156]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique system calls in attack list not present in normal\n",
    "attack_not_in_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17ecd9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = {}\n",
    "#Appending unique system calls from the normal list\n",
    "for i in range(len(train_normal_data)):\n",
    "    for j in range(len(train_normal_data[i])):\n",
    "        curr_sys_call = train_normal_data[i][j]\n",
    "        if curr_sys_call in freq_dict:\n",
    "            freq_dict[curr_sys_call] += 1 \n",
    "        else:\n",
    "            freq_dict[curr_sys_call] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "471ff556",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_normal_dict = {}\n",
    "sorted_keys = sorted(freq_dict, key=freq_dict.get)  # [1, 3, 2]\n",
    "\n",
    "for w in sorted_keys:\n",
    "    sorted_normal_dict[w] = freq_dict[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea97f106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d711cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating one hot vectors\n",
    "dict = {}\n",
    "vocab_size = 341\n",
    "\n",
    "for x in range(vocab_size):\n",
    "    arr=[]\n",
    "    arr = [0 for i in range(vocab_size)] \n",
    "    arr[x] = 1\n",
    "    dict[x] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6add9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequence size\n",
    "n = 15\n",
    "#N-Gram\n",
    "m = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c3610ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method receives a request array and returns one hot encoded version of that array\n",
    "def generate_one_hot(request):\n",
    "    temp = []\n",
    "    for sys_call in request:\n",
    "        temp.append(dict[int(sys_call)])\n",
    "    return temp\n",
    "\n",
    "# This method recevies a request array, start and  end of the request and populates x_train and y_train\n",
    "# with returned one hot version from the generate_trainSet method\n",
    "def split_request(source, target, request, start, end):\n",
    "    while(len(request)-start >= n+m):\n",
    "        source.append(generate_one_hot(request[start:end]))\n",
    "        start += m\n",
    "        end += m\n",
    "        target.append(generate_one_hot(request[start:end]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e471c34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = [] \n",
    "\n",
    "# Populating x_train and y_train with sources and targets\n",
    "for i in range(len(train_normal_data)):\n",
    "    split_request(x_train, y_train, train_normal_data[i],0,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "decd63fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147595\n",
      "147595\n",
      "833\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(len(train_normal_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "168d2973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimizing for batch size compatibility\n",
    "del x_train[147000:]\n",
    "del y_train[147000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc96b8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147000\n",
      "147000\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6034988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting x_train and y_train into np arrays\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d7d9a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147000, 15, 341)\n",
      "(147000, 15, 341)\n"
     ]
    }
   ],
   "source": [
    "#x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5858259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test data into training and testing sets\n",
    "x_train, x_test,y_train,y_test = train_test_split(x_train,y_train,test_size=0.10,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df246a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132300, 15, 341)\n",
      "(132300, 15, 341)\n",
      "(14700, 15, 341)\n",
      "(14700, 15, 341)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2fde0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps = n\n",
    "n_features = vocab_size\n",
    "numberOfUnits = 200\n",
    "\n",
    "input= Input(shape=(n_timesteps, n_features))\n",
    "\n",
    "lstm1 = LSTM(numberOfUnits,return_sequences=True, return_state=True)\n",
    "all_state_h, state_h, state_c = lstm1(input) \n",
    "states = [state_h, state_c]\n",
    "\n",
    "lstm2 = LSTM(numberOfUnits,return_sequences=True)\n",
    "all_state_h = lstm2(all_state_h,initial_state=states)\n",
    "\n",
    "dense = (Dense(n_features, activation='softmax'))\n",
    "output = dense(all_state_h)\n",
    "model_LSTM_return_sequences_return_state = Model(input,output,\n",
    "                                name='model_LSTM_all_state_h_return_state')\n",
    "model_LSTM_return_sequences_return_state.compile(loss='categorical_crossentropy', \n",
    "                                                 optimizer='adam',\n",
    "                                                 metrics=['accuracy'])\n",
    "model_LSTM_return_sequences_return_state.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c21b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, X_train, y_train , \n",
    "               X_test, \ty_test, epochs=50, \n",
    "\t\t\t\t\t\t\t        verbose=0, patience=5):\n",
    "\t# patient early stopping\n",
    "\t#es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=1, patience=20)\n",
    "\tes = EarlyStopping(monitor='val_loss', mode='min', \n",
    "\t                   verbose=1, patience=patience)\n",
    "\t# train model\n",
    "\tprint('training for ',epochs,\n",
    "\t      ' epochs begins with',\n",
    "\t\t\t\t' EarlyStopping(monitor= val_loss ',\n",
    "\t\t\t\t' patience=',patience,')....')\n",
    "\thistory=model.fit(X_train, y_train, validation_split= 0.1, epochs=epochs,  verbose=verbose, callbacks=[es])\n",
    "\tprint(epochs,' epoch training finished...')\n",
    "\n",
    "\t# report training\n",
    "\t# list all data in history\n",
    "\tprint(history.history.keys())\n",
    "\t# evaluate the model\n",
    "\t_, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "\t_, test_acc = model.evaluate(X_test, \ty_test, verbose=0)\n",
    "\tprint('\\nPREDICTION ACCURACY (%):')\n",
    "\tprint('Train: %.3f, Test: %.3f' % (train_acc*100, test_acc*100))\n",
    "\t# summarize history for accuracy\n",
    "\tplt.plot(history.history['accuracy'])\n",
    "\tplt.plot(history.history['val_accuracy'])\n",
    "\tplt.title(model.name+' accuracy')\n",
    "\tplt.ylabel('accuracy')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'val'], loc='upper left')\n",
    "\tplt.show()\n",
    "\t# summarize history for loss\n",
    "\tplt.plot(history.history['loss'])\n",
    "\tplt.plot(history.history['val_loss'])\n",
    "\tplt.title(model.name+' loss')\n",
    "\tplt.ylabel('loss')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'val'], loc='upper left')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8a68dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test(model_LSTM_return_sequences_return_state, x_train, y_train , x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os.path\n",
    "# if os.path.isfile('models/LSTM_HIDS.h5') is False:\n",
    "#     model_LSTM_return_sequences_return_state.save('models/LSTM_HIDS.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a0b5906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receives one hot represetation and returns index where value = 1\n",
    "def one_hot_decode(arr):\n",
    "    for index,num in enumerate(arr):\n",
    "        if num == 1:\n",
    "            return index\n",
    "        \n",
    "# Receives an array to append to and a 3D-array that is one hot encoded      \n",
    "def decode(arr, three_d_array):\n",
    "    for seq in three_d_array:\n",
    "        temp = []\n",
    "        for one_hot in seq:\n",
    "            temp.append(one_hot_decode(one_hot))\n",
    "        arr.append(temp)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d484a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decodes prediction done by LSTM and stores it in arr.\n",
    "def prediction_decode(arr, prediction):\n",
    "    for seq in prediction:\n",
    "        predict_temp = []\n",
    "        for one_hot in seq:\n",
    "            predict_temp.append(argmax(one_hot))\n",
    "        arr.append(predict_temp)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a9c5a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perfect match\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "def calc_belu(target, prediction):\n",
    "    reference = []\n",
    "    candidate = []\n",
    "    reference.append(target)\n",
    "    candidate.extend(prediction)\n",
    "    return sentence_bleu(reference, candidate, weights=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ccb74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2288483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddad472",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_validation_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "875aef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_validation_data)):\n",
    "    for j in range(len(train_validation_data[i])):\n",
    "        train_validation_data[i][j] = int(train_validation_data[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9359ad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "864c2457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_request_belu_score(request,start,end):\n",
    "    request_sources = []\n",
    "    request_targets = []\n",
    "    request_prediction = []\n",
    "    request_scores= []\n",
    "    \n",
    "    decoded_request_targets = []\n",
    "    \n",
    "    while(len(request)-start >= n+m):\n",
    "        request_sources.append(generate_one_hot(request[start:end]))\n",
    "        start += m\n",
    "        end += m\n",
    "        request_targets.append(request[start:end])\n",
    "    \n",
    "    i = 1\n",
    "    while(i < len(request_sources)):\n",
    "        prediction_decode( request_prediction, model_encoder_decoder.predict(request_sources[i-1:i]))\n",
    "        i += 1\n",
    "    \n",
    "    for i in range(len(request_prediction)):\n",
    "        request_scores.append(calc_belu(request_targets[i],request_prediction[i]))\n",
    "        \n",
    "    print(request_scores)\n",
    "    return request_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7cf00468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1072\n",
      "-------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nInvalid input_h shape: [1,1,100] [1,300,100]\n\t [[{{node CudnnRNN}}]]\n\t [[model_encoder_decoder/decoder_lstm/PartitionedCall]] [Op:__inference_predict_function_735290]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_validation_data)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2300\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1000\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-------------------------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m means\u001b[38;5;241m.\u001b[39mappend(statistics\u001b[38;5;241m.\u001b[39mmean(\u001b[43mcalc_request_belu_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_validation_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m))\n",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36mcalc_request_belu_score\u001b[1;34m(request, start, end)\u001b[0m\n\u001b[0;32m     15\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(request_sources)):\n\u001b[1;32m---> 17\u001b[0m     prediction_decode( request_prediction, \u001b[43mmodel_encoder_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_sources\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     18\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(request_prediction)):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nInvalid input_h shape: [1,1,100] [1,300,100]\n\t [[{{node CudnnRNN}}]]\n\t [[model_encoder_decoder/decoder_lstm/PartitionedCall]] [Op:__inference_predict_function_735290]"
     ]
    }
   ],
   "source": [
    "means = []\n",
    "\n",
    "for i in range(len(train_validation_data)-2300-1000):\n",
    "    print(f'{i+1}/{len(train_validation_data)-2300-1000}')\n",
    "    print('-------------------------------------------------------------------')\n",
    "    means.append(statistics.mean(calc_request_belu_score(train_validation_data[i],0,n)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46038382",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statistics.mean(means))\n",
    "print(statistics.mean(attack_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348d3096",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4c6428",
   "metadata": {},
   "source": [
    "#Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c648b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 0.834\n",
    "\n",
    "threshold = .85\n",
    "\n",
    "false_negative = []\n",
    "false_positive = []\n",
    "normal = []\n",
    "anomaly = []\n",
    "\n",
    "for avg in means:\n",
    "    if avg > threshold:\n",
    "        normal.append(avg)\n",
    "    else:\n",
    "        false_negative.append(avg)\n",
    "\n",
    "for avg in attack_means:\n",
    "    if avg > threshold:\n",
    "        false_positive.append(avg)\n",
    "    else:\n",
    "        anomaly.append(avg)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbceb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = 'Safe','False_Negative'\n",
    "sizes = [len(normal),len(false_negative)]\n",
    "explode = (0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f123776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = 'Attack', 'False_Positive'\n",
    "sizes = [len(anomaly),len(false_positive)]\n",
    "explode = (0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb98fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c09330",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = .91\n",
    "\n",
    "weak_t = 0.78\n",
    "\n",
    "medium_t = 0.65\n",
    "\n",
    "percentages = []\n",
    "\n",
    "def calculate_threat(avg_list):\n",
    "\n",
    "    weak_count = 0\n",
    "    medium_count = 0\n",
    "    strong_count = 0\n",
    "    green_light = 0\n",
    "\n",
    "    for i in range(len(avg_list)):\n",
    "        if avg_list[i] >= threshold:\n",
    "            green_light += 1\n",
    "        elif avg_list[i] >= weak_t:\n",
    "            weak_count += 1\n",
    "        elif avg_list[i] >= medium_t:\n",
    "            medium_count += 1\n",
    "        else:\n",
    "            strong_count += 1\n",
    "    \n",
    "\n",
    "    \n",
    "    print(f'Green Light: {green_light/len(avg_list)}')        \n",
    "    print(f'Weak threat: {weak_count/len(avg_list)}')\n",
    "    print(f'Medium threat: {medium_count/len(avg_list)}')\n",
    "    print(f'Strong threat: {strong_count/len(avg_list)}')\n",
    "    \n",
    "    percentages.append(green_light/len(avg_list)* 100)\n",
    "    percentages.append(weak_count/len(avg_list) * 100)\n",
    "    percentages.append(medium_count/len(avg_list) * 100)\n",
    "    percentages.append(strong_count/len(avg_list) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a19019",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_threat(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f8582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = 'Safe', 'Weak Threat', 'Medium Threat', 'Strong Threat'\n",
    "sizes = [percentages[0],percentages[1],percentages[2],percentages[3]]\n",
    "explode = (0.2, 0, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9332cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = []\n",
    "calculate_threat(attack_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b10a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = 'Safe', 'Weak Threat', 'Medium Threat', 'Strong Threat'\n",
    "sizes = [percentages[0],percentages[1],percentages[2],percentages[3]]\n",
    "explode = (0.6, 0, 0, 0.3)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c479b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attack_means = []\n",
    "\n",
    "for i in range((len(train_attack_data))):\n",
    "    print(f'{i+1}/{len(train_attack_data)}')\n",
    "    print('-------------------------------------------------------------------')\n",
    "    attack_means.append(statistics.mean(calc_request_belu_score(train_attack_data[i],0,n)))\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542a0fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(means)\n",
    "plt.hist(attack_means)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bdb83aa4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
